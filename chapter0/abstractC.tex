%# -*- coding:utf-8 -*-\begin{abstract}随着近年来众多大规模人工标注的图像和视频数据集的出现和深度学习技术的突破，基于深度学习的计算机视觉技术已经取得了长足的进步。然而，现有的计算机视觉技术还远远不能实现大规模的落地应用，这主要原因是由于日常生活中的媒体数据中的视觉场景通常包含大量的物体以及物体间的交互，而对复杂视觉场景的识别和理解本身存在巨大挑战。本文将针对四个不同层次的场景理解，逐步地对复杂视觉场景的识别、检测和推理进行研究。本文的关键技术路线主要包括物体分类、场景图生成、视觉描述生成、视觉检索和视觉问答等具体研究任务：\begin{asparaenum}\item 针对目前零样本物体分类模型中普遍存在的属性丢失的问题，本文提出一 种全新的零样本学习框架:属性保持的对抗学习。首次提出将图像分类和图像重建 两个相互冲突的任务分离出来。通过利用对抗网络学习使分类网络的映射向量保 持尽可能多的属性，提升对新类别的迁移能力。不仅可以逼真地重建回原始图像， 同时可以大幅度提升零样本分类的准确率。\item 为了让场景图生成任务的优化目标能够关注不同物体的重要性，本文首次 提出将场景图生成任务看成是一个多智能体协同决策问题。通过将场景图整体的 生成质量作为优化目标，考虑单个物体预测对全局场景图的影响。同时，本文提出 一种反事实基准模型，有效地对不同的物体预测赋予不同的优化梯度。不仅可以显 著提升物体的类别预测准确率，同时提升场景图整体的生成质量。\item 本文扩展现有的编码-解码框架中的空间注意力机制，提出一种全新的多层空间和通道注意力网络。通过充分考虑特征图的三个维度的信息，使得模型在生成 文本的过程中不断的关注不同的区域和通道，大大提升了编码向量的表达能力。不 仅提升了模型生成描述语句的准确性，同时帮助理解卷积神经网络中特征图的变 化过程。\item 本文通过分析目前视频片段检索框架(自顶向下模型和稀疏型自底向上模 型)的优缺点，提出一种全新的密集型自底向上的框架，可以避免现有框架的所有 缺点。通过将视频边界预测问题分解成相关性预测和边界回归两个问题，大大降低 了视频边界定位的难度。另外，我们通过设计一种基于图卷积的特征金字塔层，来 增强骨干网络的编码能力。对于两种不同的查询输入(自然语言和视频片段)，本 文提出的模型都达到了目前最好的性能。\item 对于视觉问答中长期存在的问题:模型受文本偏置影响较大，本文提出了 一种全新的反事实训练样本生成机制。这些反事实样本通过遮盖图像或者问句中 重要的区域或者单词得到。将原始样本及合成的样本一起输入到模型中训练，迫使 模型更加关注到遮盖的区域及单词，使模型做决策时依赖正确的信息，提升模型的 鲁棒性，降低对文本偏置的依赖。同时，提升模型的视觉可解释性和文本敏感性。\end{asparaenum}\keywords{复杂场景理解，零样本物体分类，场景图生成，视觉描述生成，视觉问答}\end{abstract}