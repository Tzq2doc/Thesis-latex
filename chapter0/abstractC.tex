%# -*- coding:utf-8 -*-\begin{abstract}尽管近年来计算机视觉技术已经取得了长足的进步，但是对于复杂视觉场景的感知和理解，目前的计算机模型表现远远没有达到大规模普及和落地应用的水平。为了充分地利用日常生活中海量的视觉媒体数据，复杂视觉场景的感知和理解已经逐渐成为计算机视觉领域的一个研究热点。本文将针对四个不同层次的视觉场景理解（物体识别、场景识别、场景理解和场景推理），逐步地对复杂视觉场景中视觉内容的识别、检测和推理进行研究。本文的关键技术线路主要聚焦于零样本物体分类、图像场景图生成、图像描述生成、视频片段检索和视觉问答等具体视觉场景理解任务。在此研究技术路线下，本文主要的研究内容和贡献如下：1）针对零样本物体分类模型中普遍存在的语义丢失的问题，本文提出一种全新的零样本学习网络。该网络首次引入两个相互独立的映射网络分支，将图像分类和图像重建两个原本相互冲突的任务分离出来。同时借助对抗学习，实现重建网络分支和分类网络分支之间的属性迁移。2）针对图像场景图生成模型中优化目标通常忽略不同物体的重要性差异的问题，本文提出一种全新的训练框架，首次将场景图生成任务转化成多智能体协同决策问题，从而可以直接将整个场景图质量作为模型的优化目标。同时，本文还提出了一种反事实基准模型，可以有效地计算每个物体类别预测对整体场景图的局部贡献。3）参考现有的空间注意力机制，本文首次提出通道注意力机制。同时，通过充分挖掘卷积神经网络的特征图的三个不同维度（空间、通道和层级）之间的联系，提出一种全新的空间和通道注意力网络。在图像描述生成任务中，该网络不仅极大地提升了描述语句的生成质量，同时帮助人们理解在语句生成过程中特征图的变化过程。4）针对目前视频片段检索任务中两种主流框架（自顶向下和稀疏型自底向上）的设计缺陷，本文提出了一种全新的密集型自底向上的框架。通过将动作边界定位问题分解成相关性预测和边界回归两个子问题，显著地降低了动作边界定位的难度。同时，本文提出一个基于图卷积的特征金字塔层，来进一步增强骨干网络编码能力。5）针对目前视觉问答模型忽略的两个重要特性（视觉可解释性和问题敏感性），本文提出了一种通用的反事实样本生成机制。通过遮盖图像中的重要区域或问题中的重要单词，同时更改标准答案，来合成反事实样本。通过使用原始样本和反事实样本一起对模型进行训练，迫使模型关注被遮盖的重要内容，提升模型的视觉可解释性和问题敏感性。\keywords{复杂视觉场景理解、零样本物体分类、图像场景图生成、图像描述生成、视频片段检索、视觉问答}\end{abstract}