\let \CTEX@spaceChar \relax 
\contentsline {chapter}{摘\CTEX@spaceChar \CTEX@spaceChar 要}{I}{chapter*.1}% 
\contentsline {chapter}{Abstract}{III}{chapter*.2}% 
\cftpagenumbersoff {chapter}
\contentsline {chapter}{目\CTEX@spaceChar \CTEX@spaceChar 次}{V}{chapter*.3}% 
\cftpagenumberson {chapter}
\contentsline {chapter}{插\CTEX@spaceChar \CTEX@spaceChar 图}{IX}{chapter*.4}% 
\contentsline {chapter}{表\CTEX@spaceChar \CTEX@spaceChar 格}{XI}{chapter*.5}% 
\contentsline {chapter}{\numberline {1\hspace {.3em}}绪论}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}研究内容}{4}{section.1.2}% 
\contentsline {subsection}{\numberline {1.2.1}基于属性保持对抗网络的零样本物体分类}{5}{subsection.1.2.1}% 
\contentsline {subsection}{\numberline {1.2.2}基于反事实多智能体学习的图像场景图生成}{5}{subsection.1.2.2}% 
\contentsline {subsection}{\numberline {1.2.3}基于多层空间和通道注意力网络的图像描述生成}{6}{subsection.1.2.3}% 
\contentsline {subsection}{\numberline {1.2.4}基于密集型自底向上网络的视频片段检索}{6}{subsection.1.2.4}% 
\contentsline {subsection}{\numberline {1.2.5}基于反事实样本生成的视觉问答}{7}{subsection.1.2.5}% 
\contentsline {section}{\numberline {1.3}本文组织结构}{7}{section.1.3}% 
\contentsline {section}{\numberline {1.4}本章小结}{8}{section.1.4}% 
\contentsline {chapter}{\numberline {2\hspace {.3em}}相关研究综述}{9}{chapter.2}% 
\contentsline {section}{\numberline {2.1}零样本物体分类}{9}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}零样本学习}{9}{subsection.2.1.1}% 
\contentsline {subsection}{\numberline {2.1.2}通用型零样本学习}{10}{subsection.2.1.2}% 
\contentsline {subsection}{\numberline {2.1.3}零样本学习中的域偏移问题}{10}{subsection.2.1.3}% 
\contentsline {subsection}{\numberline {2.1.4}零样本学习和对抗生成网络}{10}{subsection.2.1.4}% 
\contentsline {section}{\numberline {2.2}图像场景图生成}{11}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}场景图生成}{11}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}多智能体策略梯度}{12}{subsection.2.2.2}% 
\contentsline {section}{\numberline {2.3}图像描述生成}{12}{section.2.3}% 
\contentsline {subsection}{\numberline {2.3.1}编码-解码框架}{12}{subsection.2.3.1}% 
\contentsline {subsection}{\numberline {2.3.2}注意力机制}{13}{subsection.2.3.2}% 
\contentsline {section}{\numberline {2.4}视频片段检索}{14}{section.2.4}% 
\contentsline {subsection}{\numberline {2.4.1}视频片段检索}{14}{subsection.2.4.1}% 
\contentsline {subsection}{\numberline {2.4.2}自顶向下与自底向上}{14}{subsection.2.4.2}% 
\contentsline {section}{\numberline {2.5}图像视觉问答}{15}{section.2.5}% 
\contentsline {subsection}{\numberline {2.5.1}视觉问答模型}{15}{subsection.2.5.1}% 
\contentsline {subsection}{\numberline {2.5.2}视觉问答模型的文本偏置}{15}{subsection.2.5.2}% 
\contentsline {subsection}{\numberline {2.5.3}视觉问答模型的特性}{16}{subsection.2.5.3}% 
\contentsline {chapter}{\numberline {3\hspace {.3em}}基于属性保持的对抗网络学习的零样本物体分类方法}{17}{chapter.3}% 
\contentsline {section}{\numberline {3.1}问题描述}{17}{section.3.1}% 
\contentsline {section}{\numberline {3.2}属性保持的对抗网络学习}{19}{section.3.2}% 
\contentsline {subsection}{\numberline {3.2.1}零样本分类预备知识}{19}{subsection.3.2.1}% 
\contentsline {subsection}{\numberline {3.2.2}分类任务优化目标}{20}{subsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.2.3}重建任务优化目标}{21}{subsection.3.2.3}% 
\contentsline {subsection}{\numberline {3.2.4}对抗学习优化目标}{21}{subsection.3.2.4}% 
\contentsline {subsection}{\numberline {3.2.5}总体优化目标}{22}{subsection.3.2.5}% 
\contentsline {section}{\numberline {3.3}实验设置与性能分析}{22}{section.3.3}% 
\contentsline {subsection}{\numberline {3.3.1}零样本物体分类数据集}{22}{subsection.3.3.1}% 
\contentsline {subsection}{\numberline {3.3.2}实验设定与零样本物体分类评价指标}{23}{subsection.3.3.2}% 
\contentsline {subsection}{\numberline {3.3.3}网络模型与参数设置}{23}{subsection.3.3.3}% 
\contentsline {subsection}{\numberline {3.3.4}零样本物体分类的性能对比}{23}{subsection.3.3.4}% 
\contentsline {subsection}{\numberline {3.3.5}零样本物体分类方法分析}{24}{subsection.3.3.5}% 
\contentsline {section}{\numberline {3.4}本章小结}{27}{section.3.4}% 
\contentsline {chapter}{\numberline {4\hspace {.3em}}基于反事实的多智能体学习的图像场景图生成方法}{29}{chapter.4}% 
\contentsline {section}{\numberline {4.1}问题描述}{29}{section.4.1}% 
\contentsline {section}{\numberline {4.2}反事实的多智能体学习}{32}{section.4.2}% 
\contentsline {subsection}{\numberline {4.2.1}场景图生成中的多智能体通信}{33}{subsection.4.2.1}% 
\contentsline {subsection}{\numberline {4.2.2}反事实多智能体学习}{36}{subsection.4.2.2}% 
\contentsline {section}{\numberline {4.3}实验设置与性能对比}{39}{section.4.3}% 
\contentsline {subsection}{\numberline {4.3.1}图像场景图生成数据集与实验设定}{39}{subsection.4.3.1}% 
\contentsline {subsection}{\numberline {4.3.2}实验细节}{39}{subsection.4.3.2}% 
\contentsline {subsection}{\numberline {4.3.3}场景图生成性能分析}{40}{subsection.4.3.3}% 
\contentsline {subsection}{\numberline {4.3.4}场景图生成性能对比}{42}{subsection.4.3.4}% 
\contentsline {section}{\numberline {4.4}本章小结}{44}{section.4.4}% 
\contentsline {chapter}{\numberline {5\hspace {.3em}}基于多层空间和通道注意力网络的图像描述语句生成方法}{45}{chapter.5}% 
\contentsline {section}{\numberline {5.1}问题描述}{45}{section.5.1}% 
\contentsline {section}{\numberline {5.2}空间和通道注意力机制}{47}{section.5.2}% 
\contentsline {subsection}{\numberline {5.2.1}概述}{47}{subsection.5.2.1}% 
\contentsline {subsection}{\numberline {5.2.2}空间注意力机制}{48}{subsection.5.2.2}% 
\contentsline {subsection}{\numberline {5.2.3}通道注意力机制}{49}{subsection.5.2.3}% 
\contentsline {section}{\numberline {5.3}实验设置与性能对比}{50}{section.5.3}% 
\contentsline {subsection}{\numberline {5.3.1}图像描述语句生成数据集}{50}{subsection.5.3.1}% 
\contentsline {subsection}{\numberline {5.3.2}评价指标}{50}{subsection.5.3.2}% 
\contentsline {subsection}{\numberline {5.3.3}实验设定}{51}{subsection.5.3.3}% 
\contentsline {subsection}{\numberline {5.3.4}通道注意力机制的性能分析}{51}{subsection.5.3.4}% 
\contentsline {subsection}{\numberline {5.3.5}多层注意力机制的性能分析}{52}{subsection.5.3.5}% 
\contentsline {subsection}{\numberline {5.3.6}空间和通道注意力卷积神经网络的性能比较}{53}{subsection.5.3.6}% 
\contentsline {subsection}{\numberline {5.3.7}空间注意力和通道注意力权重的可视化}{56}{subsection.5.3.7}% 
\contentsline {section}{\numberline {5.4}本章小结}{56}{section.5.4}% 
\contentsline {chapter}{\numberline {6\hspace {.3em}}基于密集型自底向上网络的视频片段检索方法}{59}{chapter.6}% 
\contentsline {section}{\numberline {6.1}问题描述}{59}{section.6.1}% 
\contentsline {section}{\numberline {6.2}基于图特征金字塔的密集型预测}{63}{section.6.2}% 
\contentsline {subsection}{\numberline {6.2.1}骨干网络}{63}{subsection.6.2.1}% 
\contentsline {subsection}{\numberline {6.2.2}图特征金字塔层}{64}{subsection.6.2.2}% 
\contentsline {subsection}{\numberline {6.2.3}密集型头网络}{65}{subsection.6.2.3}% 
\contentsline {subsection}{\numberline {6.2.4}训练阶段和测试阶段}{66}{subsection.6.2.4}% 
\contentsline {section}{\numberline {6.3}实验设置与性能对比}{67}{section.6.3}% 
\contentsline {subsection}{\numberline {6.3.1}视频片段检索数据集}{67}{subsection.6.3.1}% 
\contentsline {subsection}{\numberline {6.3.2}评价指标}{68}{subsection.6.3.2}% 
\contentsline {subsection}{\numberline {6.3.3}实验设定}{68}{subsection.6.3.3}% 
\contentsline {subsection}{\numberline {6.3.4}视频片段检索性能对比}{68}{subsection.6.3.4}% 
\contentsline {subsection}{\numberline {6.3.5}视频片段检索性能分析}{70}{subsection.6.3.5}% 
\contentsline {section}{\numberline {6.4}本章小结}{73}{section.6.4}% 
\contentsline {chapter}{\numberline {7\hspace {.3em}}基于反事实样本生成的图像视觉问答方法}{75}{chapter.7}% 
\contentsline {section}{\numberline {7.1}问题描述}{75}{section.7.1}% 
\contentsline {section}{\numberline {7.2}反事实样本生成}{78}{section.7.2}% 
\contentsline {subsection}{\numberline {7.2.1}引言}{78}{subsection.7.2.1}% 
\contentsline {subsection}{\numberline {7.2.2}反事实样本生成}{79}{subsection.7.2.2}% 
\contentsline {section}{\numberline {7.3}实验设置与性能对比}{82}{section.7.3}% 
\contentsline {subsection}{\numberline {7.3.1}CSS对视觉问答的性能分析}{82}{subsection.7.3.1}% 
\contentsline {subsection}{\numberline {7.3.2}视觉问题方法性能对比}{83}{subsection.7.3.2}% 
\contentsline {subsection}{\numberline {7.3.3}CSS对视觉可解释性的帮助}{86}{subsection.7.3.3}% 
\contentsline {subsection}{\numberline {7.3.4}CSS对文本敏感性的帮助}{87}{subsection.7.3.4}% 
\contentsline {section}{\numberline {7.4}本章小结}{87}{section.7.4}% 
\contentsline {chapter}{\numberline {8\hspace {.3em}}总结和展望}{89}{chapter.8}% 
\contentsline {section}{\numberline {8.1}本文工作总结}{89}{section.8.1}% 
\contentsline {section}{\numberline {8.2}未来研究展望}{90}{section.8.2}% 
\contentsline {chapter}{参考文献}{93}{chapter*.64}% 
\contentsline {chapter}{攻读博士学位期间主要研究成果}{113}{chapter*.65}% 
\contentsline {chapter}{致谢}{115}{chapter*.67}% 
