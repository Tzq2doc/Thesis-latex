%# -*- coding:utf-8 -*-
\chapter{总结和展望}

\section{本文工作总结}

复杂视觉场景理解是计算机视觉领域中的一个研究热点问题。同样，计算机视觉研究的终极目标就是构建一个计算机系统，使其能够和人类一样感知和理解复杂的外界客观世界。为了能够达到人类级别的视觉场景感知和理解，我们希望该计算机系统模型至少应该具备以下三个基本能力：
\begin{asparaenum}
\item 模型能够检测和识别场景中所有的组成元素，如规则物体（object）、不规则物体（stuff）和物体间的视觉关系（visual relationship）等；

\item 模型可以对视觉场景内容进行理解和推理，并总结和归纳出知识；

\item 模型可以通过自然语言和人类之间进行交互，传递知识。
\end{asparaenum}

对于上述这些能力，本博士论文分别从四个不同的层次对复杂视觉场景进行识别和理解，具体包括：物体级别识别、场景级别识别、场景级别理解和场景级别推理等。

本文主要的研究内容与贡献如下：
\begin{asparaenum}
\item 针对目前零样本物体分类模型中普遍存在的语义丢失的问题，本文提出一种全新的零样本学习网络：基于属性保持的对抗网络。本文首次提出图像分类和图像重建是相互冲突的两个任务，并借助对抗学习实现两者之间的知识迁移，进而减缓语义丢失的问题。本文提出的零样本物体分类模型不仅可以逼真地重建回原始图像，同时可以大幅度地提升零样本物体分类的准确率。

\item 本文首次分析现有图像场景图生成模型优化目标的设计缺陷，并提出图像场景图生成任务优化目标应当具备的两个特性：整体一致性和局部敏感性。本文首次将场景图生成任务转换成一个多智能体协同决策问题，并设计了一种反事实基准模型，使得模型训练的优化目标同时满足整体一致性和局部敏感性。本文提出的图像场景图生成模型不仅可以显著地提升物体的类别预测准确率，同时提升整个场景图的生成质量。

\item 本文首次提出通道注意力机制，并结合现有的空间注意力机制，提出一种全新的多层空间和通道注意力网络。本文首次分析了卷积神经网络特征图中的三个维度（空间维度、通道维度和层级维度）对图像描述生成的影响。本文提出的图像描述生成模型不仅提升了模型生成描述语句的准确性，同时帮助理解在生成文本的过程中卷积神经网络特征图的变化过程。

\item 本文通过分析目前视频片段检索框架（自顶向下模型和稀疏型自底向上模型）的优缺点，提出一种全新密集型自底向上的框架，可以避免现有视频片段检索框架的所有缺点。同时，我们设计了一个基于图卷积的特征金字塔层，来增强骨干网络的特征编码能力。本文提出的视频片段检索模型，在两种不同的查询输入（自然语句和视频片段）形式中，都达到了当时最好的实验性能。

\item 针对目前视觉问答模型忽略的两个重要特性（视觉可解释性和问题敏感性），本文首次提出一种通用的反事实样本生成机制。本文提出的反事实样本机制不仅可以无缝地嵌入任意的视觉问答模型中来提升视觉可解释性和问题敏感性，同时可以进一步提升视觉问答模型的准确率。

\end{asparaenum}

\section{未来研究展望}

本文主要围绕复杂视觉场景的感知和理解中涉及的多个关键技术展开研究，其中仍然还有许多方向可以进一步探索，帮助计算机系统达到像人类一样的视觉场景感知和理解能力。具体来说，有以下一些方向：
\begin{asparaenum}
\item \textbf{设计更加有效的目标检测和分割算法}：目标检测和分割（如：目标检测、语义分割和实例分割等）是计算机视觉研究领域中的经典的研究问题。它们不仅仅是物体层次识别的关键，也是后续场景层次的识别和理解的基础。尽管过去十年内目标检测和分割算法已经取得了长足的进步，但是离大规模的民用还需要进一步提升算法的准确率、检测速度以及鲁棒性等。

\item \textbf{设计更加轻便的网络结构}：尽管目前的视觉场景感知和理解算法已经可以取得较好的性能，但是几乎所有的模型都依赖于强大的计算资源（如：大规模GPU）。另一方面，随着手机、穿戴式设备等便携设备已经成为日常生活中最为常见的计算设备，而这些设备都只能依靠CPU等轻量化的计算资源。因此，如何设计更加轻便的网络结构，使得这些视觉场景感知和理解算法能够直接应用于便携设备，将极大地便利人们的日常生活，推动社会的进步。

\item \textbf{使用更少的监督训练信息}：在“大数据时代”下，每分钟都会有大量的图像和视频等视觉媒体数据出现在互联网中。然而，这些海量的媒体数据通常不含有任何的人工监督信息标注或者只含有少量的人工监督信息标注。如何设计算法使得计算机模型只需要使用更少的监督信息（如：弱监督学习、无监督学习或自监督学习等），可以帮助模型充分地利用互联网中的海量媒体数据。

\item \textbf{将图像、视频等二维视觉场景推广到三维视觉场景}：与图像、视频等二维视觉场景相比，三维视觉场景包含更加丰富的视觉信息，可以辅助对整个视觉场景的感知和理解。例如，当两个物体之间存在较大的交并比（Intersection over Union, IoU）时，在二维视觉场景下我们通常认为两者之间具有很强的相关性。然而，在三维视觉场景中，当两个物体的深度完全不同，两个物体之间的相关性则很小。因此，对三维视觉场景下的感知和理解同样具有重要的研究意义和研究价值。

\end{asparaenum}
