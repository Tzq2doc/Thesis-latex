%# -*- coding:utf-8 -*-
\chapter{总结和展望}

\section{本文工作总结}

计算机视觉技术是人类社会迈向人工智能时代至关重要的一步。随着海量视觉媒体数据的出现，基于深度学习的计算机视觉技术取得了长足的进步。计算机视觉研究的终极目标就是设计一个计算机系统，能够和人类一样感知复杂的外界客观世界。为了达到人类级别的视觉场景感知和理解，我们希望该系统模型具备三个基本能力：
\begin{asparaenum}
\item 模型能够检测和识别场景中所有的组成元素，如规则物体（object）、不规则物体（stuff）和视觉关系（visual relationship）等；

\item 模型可以对视觉场景内容进行理解和推理，并总结和归纳出知识；

\item 模型可以通过自然语言和人类之间进行交互。
\end{asparaenum}

对于上述这些能力，我们从四个不同的层次对复杂视觉场景进行识别和理解，具体包括：物体识别、场景识别、场景理解和场景推理等。

本文主要主要的研究内容与贡献如下：
\begin{asparaenum}
\item 针对目前零样本物体分类模型中普遍存在的属性丢失的问题，本文提出一种全新的零样本学习框架：属性保持的对抗学习。首次提出将图像分类和图像重建两个相互冲突的任务分离出来。通过利用对抗网络学习使分类网络的映射向量保持尽可能多的属性，提升对新类别的迁移能力。不仅可以逼真地重建回原始图像，同时可以大幅度提升零样本分类的准确率。

\item 为了让场景图生成任务的优化目标能够关注不同物体的重要性，本文首次提出将场景图生成任务看成是一个多智能体协同决策问题。通过将场景图整体的生成质量作为优化目标，考虑单个物体预测对全局场景图的影响。同时，本文提出一种反事实基准模型，有效地对不同的物体预测赋予不同的优化梯度。不仅可以显著提升物体的类别预测准确率，同时提升场景图整体的生成质量。

\item 本文扩展现有的编码-解码框架中的空间注意力机制，提出一种全新的多层空间和通道注意力网络。通过充分考虑特征图的三个维度的信息，使得模型在生成文本的过程中不断的关注不同的区域和通道，大大提升了编码向量的表达能力。不仅提升了模型生成描述语句的准确性，同时帮助理解卷积神经网络中特征图的变化过程。

\item 本文通过分析目前视频片段检索框架（自顶向下模型和稀疏型自底向上模型）的优缺点，提出一种全新的密集型自底向上的框架，可以避免现有框架的所有缺点。通过将视频边界预测问题分解成相关性预测和边界回归两个问题，大大降低了视频边界定位的难度。另外，我们通过设计一种基于图卷积的特征金字塔层，来增强骨干网络的编码能力。对于两种不同的查询输入（自然语言和视频片段），本文提出的模型都达到了目前最好的性能。

\item 对于视觉问答中长期存在的问题：模型受文本偏置影响较大，本文提出了一种全新的反事实训练样本生成机制。这些反事实样本通过遮盖图像或者问句中重要的区域或者单词得到。将原始样本及合成的样本一起输入到模型中训练，迫使模型更加关注到遮盖的区域及单词，使模型做决策时依赖正确的信息，提升模型的鲁棒性，降低对文本偏置的依赖。同时，提升模型的视觉可解释性和文本敏感性。

\end{asparaenum}

\section{未来研究展望}

本文主要围绕复杂视觉场景的感知和理解中涉及的多个关键技术展开研究，其中仍然还有许多方向可以进一步探索，帮助计算机系统达到像人类一样的视觉场景理解能力。具体来说，有以下几点：
\begin{asparaenum}
\item \textbf{设计更加有效的目标检测和分割算法}：目标检测和分割（如：语义分割、实例分割和全景分割等）是计算机视觉领域一个经典的研究问题，它不仅仅是物体层次识别的关键，也是后续场景层次的识别和理解的基础。尽管过去十年内目标检测和分割算法已经取得了长足的进步，但是离大规模的民用还需要进一步提升算法的准确率、检测速度以及鲁棒性。

\item \textbf{设计更加轻便的网络结构}：尽管目前的视觉场景感知和理解算法已经可以取得较好的性能，但是基本所有的模型都依赖于强大的计算能力（如：GPU）。另一方面，手机等便携设备已经成为日常生活中最常见的计算设备，而这些设备只能依靠CPU等轻量化的计算资源。如何设计更加轻便的网络结构，使得这些视觉场景感知和理解算法能够直接应用于便携设备，将极大地便利人们的日常生活，推动社会的进步。

\item \textbf{使用更少的监督信息}：“大数据时代”下，每分钟都会有大量的新图像和视频在互联网上出现。然而，这些海量的媒体数据都不含有任何的人工标注。通过设计算法使用更少的监督信息（如：弱监督学习、无监督学习或自监督学习等），是模型可以充分利用互联网上的海量媒体数据。

\item \textbf{将图像、视频等二维视觉场景推广到三维视觉场景}：与图像、视频等二维视觉场景相比，三维视觉场景包含更多丰富的信息，帮助对视觉场景的感知和理解。例如，当两个物体之间存在较大的IoU时，在二维场景下我们通常认为两者之间具有很强的相关性。然而，如果两个物体的深度完全不同时，两个物体之间的相关性又完全不同。因此，三维视觉场景下的感知和理解同样具有重要的研究意义和研究价值。

\end{asparaenum}
